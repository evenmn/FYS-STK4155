\section{Methods} \label{sec:methods}

\subsection{Resampling techniques} \label{sec:resampling}
A resampling technique is..
There are plenty of resampling techniques, and we have already went through several of them in this course:
\begin{itemize}
\item{Validation set approaches}
\item{Leave one out validation}
\item{Jackknife resampling}
\item{K-fold validation}
\item{Bootstrap method}
\item{Blocking method}.
\end{itemize}
For this particular project we have been focusing on the bootstrap and the k-fold validation methods, so here I will cover them only

\subsubsection{Bootstrap method} \label{sec:bootstrap}

\subsubsection{K-fold validation method} \label{sec:kfold}


\subsection{Singular Value Decomposition (SVD)} \label{sec:svd}

\subsection{Minimization methods} \label{sec:minimization}
When the interaction term is excluded, we know which $\alpha$ that corresponds to the energy minimum, and it is in principle no need to try different $\alpha$'s. However, sometimes we have no idea where to search for the minimum point, and we need to try various $\alpha$ values to determine the lowest energy. If we do not know where to start searching, this can be a time consuming activity. Would it not be nice if the program could do this for us?

In fact there are multiple techniques for doing this, where the most complicated ones obviously also are the best. Anyway, in this project we will have good initial guesses, and are therefore not in need for the most fancy algorithms. 

\subsubsection{Gradient Descent} \label{sec:gd}
Perhaps the simplest and most intuitive method for finding the minimum is the gradient descent method (GD), which reads
\begin{equation}
\label{eq:GD}
\alpha^+=\alpha - \eta\cdot\frac{d\langle E(\alpha)\rangle}{d\alpha}.
\end{equation}
where $\alpha^+$ is the updated $\alpha$ and $\eta$ is a step size. The idea is that one finds the gradient of the energy with respect to a certain $\alpha$, and moves in the direction which minimizes the energy. This is repeated until one has found an energy minimum, where the energy minimum is defined as either where $\frac{d\langle E(\alpha)\rangle}{d\alpha}$ is smaller than a given tolerance, or the energy fluctuates around a value are smaller than a tolerance, and thus changes minimally.
\par 
\vspace{3mm}

To implement equation \ref{eq:GD}, we need an expression for the derivative of $E$ with respect to alpha:

\begin{equation}
	\label{eq:E_L_der_wrt_alpha}
	\bar{E_{\alpha}} = \frac{d \langle E (\alpha) \rangle}{d \alpha}.
\end{equation}
By using the expression for the expectation value for the energy $ \langle E (\alpha) \rangle$ in equation \ref{eq:exp_EL} 

\begin{equation}
	\label{eq:exp_EL}
	\langle E (\alpha) \rangle = \frac{ \langle \psi_T(\alpha) | H | \psi_T(\alpha)  \rangle}{ \langle \psi_T(\alpha)  |  \psi_T(\alpha)  \rangle }
\end{equation}
and applying the chain rule of differentiation, it can be shown that equation \ref{eq:E_L_der_wrt_alpha} is equal to equation \ref{eq:E_L_der_wrt_alpha_expression}

\begin{equation}
	\label{eq:E_L_der_wrt_alpha_expression}
	\bar{E_{\alpha}} = 2 \bigg[\langle E_L (\alpha)  \frac{ \bar{\psi_{\alpha}}}{\psi_{\alpha}}\rangle - \langle E_L (\alpha) \rangle \langle \frac{\bar{\psi_{\alpha}}}{\psi_{\alpha}} \rangle\bigg]
\end{equation}
where

\begin{equation}
	\bar{\psi_{\alpha}} = \frac{d \psi (\alpha)}{d \alpha}.
\end{equation}

The algorithm of this minimization method is thus as follows:

\lstset{basicstyle=\scriptsize}
\begin{lstlisting}

for(max number of iterations with minimizing)
	
	do M Monte Carlo cycles
	calculate E and dE/dalpha 
	
	Check if dE/dalpha < eps or alpha fluctuation over the last 5 steps is < eps
	
	
		if yes, print optimal alpha and break loop
		if no, continue to next iteration


\end{lstlisting}